{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lecture Notes for session conducted on August 17, 2022\n",
        "\n",
        "https://www.scaler.com/academy/mentee-dashboard/class/34222/session\n",
        "\n",
        "**Content**\n",
        "\n",
        "1.   Code Walkthrough- Time Series.\n",
        "2.   Time Series Decomposition.\n",
        "3.   Stationarity of Time Series.\n",
        "4.   De-Trending Time Series.\n",
        "5.   Auto correlation Function (ACF)."
      ],
      "metadata": {
        "id": "TJZ-3vAUjCBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Good Reads:***\n",
        "\n",
        "An interesting resource that talks about Time Series analysis on live data. Highly recommended to read this blog by the time we complete Time Series Sessions.\n",
        "\n",
        "https://www.uber.com/en-IN/blog/forecasting-introduction/"
      ],
      "metadata": {
        "id": "eIcVVaWNMPR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Walkthrough - Time Series:\n"
      ],
      "metadata": {
        "id": "2ExToxIIk_-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Earlier, we had studied Linear Regression from Probabilistic perspective using Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP).\n",
        "- We also looked at a Linear Regression from Geometric and Optimization perspective as well.\n",
        "- Classical Time Series Forecasting is Special case of Linear Regression.\n",
        "<img src='https://drive.google.com/uc?id=1ECNBRfMA-dxyb_6K_l7-iBE0I31b6Sch'>\n"
      ],
      "metadata": {
        "id": "xT2g-rkZSUxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset:"
      ],
      "metadata": {
        "id": "_6ir3eMRYiuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is of Monthly sales volume. So Granularity is month i.e. each datapoint corresponds to single month's data.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1iRGUIdfUphqyV_zAn5MvgQyqIK01_jJj'>\n",
        "\n",
        "*Link to Dataset:*\n",
        "\n",
        "https://drive.google.com/uc?id=1-pOuGRd8zuAUKBll-1xkr7_867NwoWHg"
      ],
      "metadata": {
        "id": "nsRV68feUQra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations:"
      ],
      "metadata": {
        "id": "jN259W5zYqJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Looking at this plot, we can observe that there are outliers, an increasing trend, some missing values and seasonality as well.\n",
        "    <img src='https://drive.google.com/uc?id=1Ch7lOb0CejXU5XaP0fBBVj9nDoLIP_Kg'>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_s-637WcWUHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputations:"
      ],
      "metadata": {
        "id": "9C0Y7YLdYupq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Simple Imputation:"
      ],
      "metadata": {
        "id": "ZLzE3eJ4Yz9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- We can use Mean Imputation for missing data.\n",
        "    <img src='https://drive.google.com/uc?id=14yuaJ_xR7Lzrx-os8138tOpYV-1kONB_'>\n",
        "- In the above plot, we can see the imputed data in 'Green color' and original data in 'Orange color'.\n",
        "\n",
        "However, mean imputation has some issues:\n",
        "- Mean imputation takes global mean. So it has lookahead bias.\n",
        "- There are sudden spikes in imputed data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b2EGMXMSWFAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Linear Interpolation:"
      ],
      "metadata": {
        "id": "QokOO4KnY51Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imagine we have a plot as shown below and some of the data is missing for timestamp $t$.\n",
        "    <img src='https://drive.google.com/uc?id=1A_M8ASv4AqpKJMkaIMiV3cPJBLdh8amg'>\n",
        "- Linear Interpolation says that we just draw a line from $(t-1)$ to $(t+1)$ and pick that value of $t$ that falls on this line.\n",
        "- So we are interpolating/predicting what the value will be at timestamp $t$.\n",
        "\n",
        "*Note:*\n",
        "\n",
        "Simply speaking, Linear Interpolation is Centered Moving Average (CMA) with m = 1.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CU4oBZ0-Y51S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the following plot, we used interpolation.\n",
        "    <img src='https://drive.google.com/uc?id=1gIT7V9pMNnBYgbn_PqZOTUFP54zbFQ7W'>\n",
        "- Imputed values appear in 'Green color' and original in 'Orange color'.\n",
        "- We notice that there are no more spikes now in the imputed data.\n",
        "- There will be slight lookahead bias though as we lookahead only a few timestamps.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mIQdEdxzdAmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** What if more values are missing?\n",
        "\n",
        "***Answer***:\n",
        "- We can use Linear Interpolation as well.\n",
        "    <img src='https://drive.google.com/uc?id=1Qs1QW1qIU6ilLG7FNVveTc-wob6nnQJr'>\n",
        "- For e.g. if we have values for $(t-2)$ and $(t+1)$ and missing for $(t-1)$ and $(t)$.\n",
        "- Linear Interpolation connects $(t-2)$ and $(t+1)$ and then find out which value of $(t-1)$ and $(t)$ fall on this line.\n",
        "\n",
        "*Note:*\n",
        "\n",
        "If more data is missing, then Linear Interpolation tends to be bad."
      ],
      "metadata": {
        "id": "VtE2jML2Y51U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outlier Detection and Anomalies:"
      ],
      "metadata": {
        "id": "hj43MMUIeKB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plot of sales data, shows us 2 outliers.\n",
        "  <img src='https://drive.google.com/uc?id=1QNbUgVtiVkSbubx-bnwt5eG-wZ7WTNAt'>\n",
        "- If we plot histogram of sales data, we can see 2 extreme values. So we could clip outliers using percentiles.\n",
        "  <img src='https://drive.google.com/uc?id=1dd-TntH90riS_RbBeQFzBNooW33KF7PS'>\n",
        "- After clipping $98^{th}$ and $2^{nd}$ percentiles, we get trend that looks much sensible.\n",
        "<img src='https://drive.google.com/uc?id=1Nskzjd32HZ23n9WLiwpb_Mh606SNWwvU'>\n",
        "\n",
        "But why does this happen?\n",
        "\n",
        "- Scale has changed after outlier treatments. So the trend is much more visible.\n",
        "- Data is now much more zoomed with reduction in scale.\n"
      ],
      "metadata": {
        "id": "2yV3QVc7eKCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Moving Averages:"
      ],
      "metadata": {
        "id": "DVpqBP3TiG0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Quick Recap:"
      ],
      "metadata": {
        "id": "pxSUh-TyiRAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In simple moving average there is no lookahead bias.\n",
        "  <img src='https://drive.google.com/uc?id=1xB4sdECqPEUXMeLexU6MTklO4XL_WpVV'>\n",
        "- Weighted moving average is a very powerful technique for Times Series forecasting.\n",
        "  <img src='https://drive.google.com/uc?id=1mD2T77BrONW95iDysUPhN_iRiYOdNgBL'>\n",
        "- Centered Moving Average (CMA) is used to remove outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "tA_6zcFsiT6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question***: Why is it $2m+1$ and not $2m$ in CMA?\n",
        "\n",
        "***Answer:***\n",
        "\n",
        "- Imagine we have data from $x_{(t-m)}...x_{t}...x_{(t+m)}$.\n",
        "- Formula for CMA assumes that there are m values before $x_{t}$, m values after $x_{t}$ and $x_{t}$ as well. So, we have $2m+1$ values.\n",
        "- If we don't have $x_{t}$, then we can use $2m$."
      ],
      "metadata": {
        "id": "oiaZf24xkw3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Rolling Mean:"
      ],
      "metadata": {
        "id": "dL1ipA7tl__N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here, we have used simple moving average with window = 3 i.e. to predict $\\hat{x}_t$ we will use $\\hat{x}_{t-1}, \\hat{x}_{t-2}, \\hat{x}_{t-3}$\n",
        "  <img src='https://drive.google.com/uc?id=1rgclfmNOi-bqNhy61dCy7UgGhYcsRz8b'>\n",
        "\n",
        "Key observations from the plot:\n",
        "- Spikes are smoothened.\n",
        "- There is a leading effect. The plot seems to have shifted to the right. This\n",
        " happens when we are predicting values. We take past 3 datapoints and calculate average.\n",
        "- The 'Orange plot' (Smoothened data) is shifted from original. There is missing data at the beginning. For first 3 datapoints in the original data, we do not have 3 datapoints in the past.\n",
        "\n",
        "\n",
        "*Note:*\n",
        "\n",
        "- If m increases with center=False, then jaggedness is reduced.\n"
      ],
      "metadata": {
        "id": "ibrlUEWrmMhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trend:"
      ],
      "metadata": {
        "id": "URYMdVUMr8X1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** If we want to get proper trend line, what ML technique can we use?\n",
        "\n",
        "***Approach:***\n",
        "\n",
        "We could use Linear Regression where $x_i$ = Month number and $y_i$ = Sales volume.\n",
        "\n"
      ],
      "metadata": {
        "id": "wREJk6etqLK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Intuitively, we have increasing trends, decreasing trends, changing trends and even a flat trend.\n",
        "  <img src='https://drive.google.com/uc?id=1pPkvjDkW9AU5apcn7OPTFM3mKut5xAnc'>\n"
      ],
      "metadata": {
        "id": "S7qRk8GMsD5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seasonality:"
      ],
      "metadata": {
        "id": "vJ8MhH8Ushwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seasonality is all about some pattern happening with some recurring structure.\n",
        "  <img src='https://drive.google.com/uc?id=1Hqoj5zkRWEacTRBtpXjFkI5Dg-Nu2YFC'>\n",
        "- For e.g. during holiday seasons in 2003, 2004 and 2005 we could see more sales in comparison with other months of the years.\n",
        "  <img src='https://drive.google.com/uc?id=1Zp0M9kMSrGZPoLzB67oK1l0EKB6Cuxf7'>\n",
        "- In monthy data, we could see people spending more money in the beginning of the month and less by end of the month. This could also be the situation in Yearly data for countries like India where spending is more during Diwali.\n",
        "- In reality, there could be more than one seasonality."
      ],
      "metadata": {
        "id": "SjWjxBpIshwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decompose a Time Series:"
      ],
      "metadata": {
        "id": "gbhsCjv_pwtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Additive Time Series Decomposition:"
      ],
      "metadata": {
        "id": "Zp6F841hu5Aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We want to take a Time Series and break it down into different components:\n",
        "$$x(t) = b(t) + s(t) + e(t)$$\n",
        "  <img src='https://drive.google.com/uc?id=1VNAoK3oCnxxQjI3S-OAO1EseLLbGheT6'>\n",
        "- $b(t) \\to $: Trend, $s(t) \\to $: Seasonality and $e(t) \\to $: Error/Noise.\n",
        "- This is often referred to as Additive Time Series Decomposition method.\n",
        "- From Regression perspective, it looks like:\n",
        "$$y_{i} = w_{0} + w_{1}x_{i1}+...+ w_{d}x_{id} + \\epsilon_{i}$$\n",
        "- Here some features gives us trend information, some features give seasonality information and $\\epsilon_{i}$ is the irreducible error."
      ],
      "metadata": {
        "id": "TUrD7QtruToI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Error term could be determined as:\n",
        "$$e(t) = x(t) - [ s(t) + e(t) ]$$\n",
        "  <img src='https://drive.google.com/uc?id=1aRzLH4tUg0OBxCN-HXw271RII-PAHk5g'>\n",
        "- If we plot distribution of these error, ideally it will be Gaussian with some mean and small standard deviation."
      ],
      "metadata": {
        "id": "oA5i_vy-xM2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here, statsmodel is used to decompose a Time Series.\n",
        "  <img src='https://drive.google.com/uc?id=1WOCacbUKUCFN6dET-th1yv3WG-WjfwXu'>\n",
        "- The Trend was obtained using Smoothing technique using a large window size."
      ],
      "metadata": {
        "id": "--lpN7UxybsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If we plot histogram of residuals, it looks Normally distributed. But we can't jump to conclusion yet and mean is -3.\n",
        "  <img src='https://drive.google.com/uc?id=19NKvhcUzqtcDVaFHbX2idBzjrWUXKmI5'>\n",
        "\n",
        "***Question:*** Should we be concerned that mean $\\neq$ 0?\n",
        "\n",
        "***Answer:*** No, it does not matter in this case.\n",
        "\n",
        "- If we look at the scale of data, it ranges from 7500 to 15K. So, -3 is very very small compared to the observations that we have. Hence we can ignore that mean $\\neq$ 0.\n",
        "- Suppose, we have mean = -350, then it would have been a concern.\n",
        "\n"
      ],
      "metadata": {
        "id": "iJWz6x9zzMDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiplicative Time Series Decomposition:"
      ],
      "metadata": {
        "id": "oUFW-KiCvDkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We also have Multiplicate Time Series Decomposition method.\n",
        "$$x(t) = b(t) * s(t) * e(t)$$\n",
        "  <img src='https://drive.google.com/uc?id=1-GDaWr0UPmzrxvEF25Pasgnnot77NQ88'>\n",
        "- These are not much used in practise. It typically occurs when we have pattern as shown in the figure above.\n",
        "- It is converted to additive method using Log transformation. We take log on both sides.\n",
        "- So $x(t) = b(t) * s(t) * e(t)$ becomes:\n",
        "$$log(x(t)) = log(b(t)) + log(s(t)) + log(e(t))$$"
      ],
      "metadata": {
        "id": "0ZwnoVJh05xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stationarity of Time Series:"
      ],
      "metadata": {
        "id": "BCs4aMYarCwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What does Stationarity means?"
      ],
      "metadata": {
        "id": "Jp0x3oCHvMZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If various parameters like mean, variance, standard deviation, amplitude, frequency of a Time Series are not a function of time (i.e. not dependent on time), then we say it's a stationary Time Series.\n",
        "  <img src='https://drive.google.com/uc?id=1O7SbWIf9bIB0pbku0ig0Wwq8iFlXoknX'>\n"
      ],
      "metadata": {
        "id": "rI-y4ifQrF83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** If a Time Series has trend will it be Stationary or non-Stationary?\n",
        "\n",
        "***Answer:*** It will be non-Stationary because if we are given time $(t)$, we can predict its amplitude."
      ],
      "metadata": {
        "id": "vrT-DrkesrJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** If a Time Series has Seasonality will it be Stationary or non-Stationary?\n",
        "\n",
        "***Answer:*** It will be non-Stationary as we can predict $x(t)$ given a specific time $(t)$."
      ],
      "metadata": {
        "id": "A_ilCi8-tXPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plots for Stationary and Non-Stationary Time Series:"
      ],
      "metadata": {
        "id": "XEwKOrHdvYQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Examples of Stationary and Non-Stationary Time Series:\n",
        "  <img src='https://drive.google.com/uc?id=1YCMLBgqhXfJK5fp2bz4c2NYnaY4MI7z3'>\n",
        "- `a, c, e, f, :` Not stationary\n",
        " - either have a trend, or\n",
        " - mean changing with time.\n",
        "- `d, h:` Not stationary\n",
        " - Seasonality\n",
        "- `i:` Not stationary\n",
        " - Has a trend\n",
        " - Variance is also not stable\n",
        " - Season\n",
        "- `b:`\n",
        " Stationary\n",
        " - There is 1 outlier\n",
        " - Can't say anything about mean; seems to be just noise.\n",
        "- `g:` Stationary\n",
        "  - Predicting this is dicey, so we assume it to be stationary, and try building model, and seeing if it performs.\n",
        "  - Looks like a cyclic time series. But these are not at regular intervals.\n",
        "  - So, even though there  is some seasonality, it can't be predicted.\n"
      ],
      "metadata": {
        "id": "ApcXsvkJttJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visual Analysis for Stationarity:"
      ],
      "metadata": {
        "id": "79Fw5U1zvkqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Visual analysis is always tricky and often mis-leading.\n",
        "  <img src='https://drive.google.com/uc?id=14fuWVkELelOU2FREJQc0FBdyATyYapUD'>\n",
        "- There are tests like Dickey Fuller Test or Augmented Dickey Fuller Tests.\n",
        "- In these tests, Null Hypothesis is that Time Series is non-Stationary.\n",
        "- If the p-value < $5\\%$, then we reject the Null Hypothesis."
      ],
      "metadata": {
        "id": "H4MKC18evkqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### De-Trending:"
      ],
      "metadata": {
        "id": "pTfqYqgnHRhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let $x(t)$ be a non-Stationary Time Series where:\n",
        "$$x(t) = b(t) + s(t) + e(t)$$\n",
        "  <img src='https://drive.google.com/uc?id=1aQk79vbiWWJXbQxuAjg0mkP4vSNrwFvA'>\n",
        "- Fundamentally Trend $b_{(t)}$ can be written as $m*t+c$ assuming that the trend is linear and either increasing or decreasing. So we can write the above equation as:\n",
        " $$x(t) = [m*t+c] + s(t) + e(t)$$\n",
        "- If we take derivative wrt to $(t)$:\n",
        "$$x'_{t} = \\frac{d{x(t)}}{d(t)} = m + \\frac{d{s(t)}}{d(t)} + \\frac{d{e(t)}}{d(t)}$$\n",
        "- Sometimes, we also write it as:\n",
        "$$x'(t) = \\frac{d{x(t)}}{d(t)} = m + s'(t) + e'(t)$$\n",
        "- After derivative, trend in gone and we are left with derivative of Seasonality and Irreducible error.\n",
        "- Thus, we have de-trended the Time Series data."
      ],
      "metadata": {
        "id": "oL9enpyBHRhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** $x(t)$ is non-Stationary. So how do we compute the derivative?\n",
        "\n",
        "***Answer:***\n",
        "- Derivative is computed as:\n",
        "\n",
        "$$\\frac{dx(t)}{d(t)} = \\underset{\\Delta{t}\\to 0}{lim} \\ \\frac{x(t+\\Delta{t}) - x(t)}{\\Delta{t}}$$\n",
        "- $\\because$ time interval is Monthly:\n",
        "$$\\frac{dx(t)}{d(t)} = \\frac{x(t+1) - x(t)}{1}$$\n",
        "- So we are differencing every value with it's next value.\n",
        "  <img src='https://drive.google.com/uc?id=1FpR67HIPPDq2RWQausZVEC9RTGH5oKBD'>\n",
        "\n",
        "- Simple differencing is approximately equal to taking derivative which is approximately equal to de-trending.\n",
        "- In a de-trended line, we can easily spot seasonality.\n",
        "  <img src='https://drive.google.com/uc?id=1HtRx1wWjhmo9MenLEo8CXaZYkxRD-PvV'>\n"
      ],
      "metadata": {
        "id": "1qGKutY4KtnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** How is error term a function of time? If it is a function of time, then it means we can get the error as well. Then how is is irreducible?\n",
        "\n",
        "***Answer:***\n",
        "- Given a value of $(t)$, we can find with the error is. But we cannot make future predictions of errors.\n",
        "<img src='https://drive.google.com/uc?id=1c9w_1vFD1ryYBcCmO_5mvzNQzIXgxaRb'>\n",
        "\n",
        "\n",
        "- Error is non-predictable, but still a function of time."
      ],
      "metadata": {
        "id": "i9ohXN2Md-4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** But why are we interested in de-trending? Isn't de-trending means loosing on useful insights?\n",
        "\n",
        "***Answer:***\n",
        "\n",
        "- De-trending is part of fitting the model. Model is additive and a combination of:\n",
        "$x(t) = b(t)+s(t)+e(t)$\n",
        "   <img src='https://drive.google.com/uc?id=1kMK5uTbGUAZtu294bgSZybrbjjbHhGCG'>\n",
        "- $1^{st}$, we have to de-trend Time Series to find if there's any seasonality.\n",
        "- We would further de-seasonalize as we want to do error analysis.\n"
      ],
      "metadata": {
        "id": "wu5_iTQvjd4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### De-Seasonalize:"
      ],
      "metadata": {
        "id": "n3RcvKDwmRoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Intuition:"
      ],
      "metadata": {
        "id": "9-ptOv5GmU_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seasonality means that $y_{t} \\approx y_{t-m}$, when we take a de-trended Times Series.\n",
        "  <img src='https://drive.google.com/uc?id=1CG8kNtSOU2XDY1tix6tBmKTLiJfByBQs'>\n",
        "- Similarly, $y_{t-1} \\approx y_{t-m-1}$. We can then say that we have seasonality of $m$.\n",
        "- For e.g. in the monthly sales data:\n",
        "$$Sales_{(Jan \\ 20)} \\approx Sales_{(Jan \\ 21)} \\approx Sales_{(Jan \\ 22)}$$\n",
        "- Then we can say that we have seasonality of 12 months.\n",
        "- Seasonality is obtained by m-differencing, where $m$ is the time difference between repetition of pattern.\n",
        "  <img src='https://drive.google.com/uc?id=1xn0L8ocwOiQUt8SalTv_iOj70VJ7M-wI'>\n",
        "\n",
        "**Note:** 1-differencing gives us  trend and m-differencing gives us seasonality."
      ],
      "metadata": {
        "id": "FcOxU3m6mRo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### How to find $m$?:"
      ],
      "metadata": {
        "id": "LcGTGpUJp9ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Interview Question:*** How to figure $m$ assuming that we have de-trended data?\n",
        "\n",
        "***Approaches:***\n",
        "- Find local minima and local maxima.\n",
        "- Find 1 local miniman and try to find next local minima.\n"
      ],
      "metadata": {
        "id": "I226IyIDwq2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Another Approach:***\n",
        "- Shifting Time Series by 1 units of time $m$ number of times. Also known as $lag$ in Time Series.\n",
        "  <img src='https://drive.google.com/uc?id=18MfwMt1sp3hF4_mWDK-VOOfa75JGxPzn'>\n",
        "- For a Time Series $x(t)$, let $x^i(t)$ be the Time Series lagged by '$i$' units.\n",
        "- When $i=m$, the 2 Time Series overlap more or less. If the values are same, we will create a table that stores the Pearson Correlation Coeffecients (PCC) of $x(t)\\ and \\ x^i(t)$.\n",
        "  <img src='https://drive.google.com/uc?id=1FkQXjz-4Z9B4J6SLacMD3MSI3uDsQ9v0'>\n",
        "- When $i=m$, PCC will be very close to 1.\n",
        "\n",
        "*Note:*\n",
        "- Beauty of Correlation Coefficient is that it lies between -1 and +1.\n",
        "- PCC captures linearity.\n"
      ],
      "metadata": {
        "id": "ldnd-kh8p9mJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Auto Correlation Function:"
      ],
      "metadata": {
        "id": "CUYr2bf4zEcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the below graph, we are plotting the value of correlation against various values of lag.\n",
        "  <img src='https://drive.google.com/uc?id=1jJMlp4nfFVOdyJjlId4M1GbNZ6opMsyt'>\n",
        "- Even if we don't have perfect lag, there is a linear relationship.\n",
        "- Such plots are known as Auto Correlation plots as we are taking correlation of Time Series with itself for some lag.\n",
        "- Mathematically, $f(lags) = correlation \\ coefficient$. This function is called as Auto Correlation Function (ACF).\n"
      ],
      "metadata": {
        "id": "HQlLOXBdy8LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- At zero, correlation of a function with itself is 1.\n",
        "  <img src='https://drive.google.com/uc?id=18f7kYWAYV_Z3T8TH4ZdkRVNmQLTKGvQZ'>\n",
        "- At 12, we have the next highest value. This says that if we take Time Series data of mobile sales and move it by 12 units (months), the Time Series will have highest correlation with itself.\n",
        "- Same is the case at 6 units. So, there is a 6 months trend as well as 12 months trend.\n",
        "- In a function to find $m$, we would ignore correlation at 0. Then find the $2^{nd}$ highest and $3^{rd}$ highest (12 and 6 in our case).\n",
        "- Obviously there will be multiples of 12 and 6 in data.\n",
        "- Now check if there are non-multipliers of 6 and 12. If they don't exist, then we can conclude that we have 6 months seasonality and 12 months seasonality.\n",
        "\n",
        "*Note:*\n",
        "\n",
        "It is better to do ACF plots on de-trended data."
      ],
      "metadata": {
        "id": "tXLs2z6c_p28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Note*"
      ],
      "metadata": {
        "id": "BiolflsTfvuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following topics will be covered in next lecture:\n",
        "\n",
        "- PACF.\n",
        "- Train-Test split.\n",
        "- Model building."
      ],
      "metadata": {
        "id": "6lClAUcPf6Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9ex6ukU89WE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}