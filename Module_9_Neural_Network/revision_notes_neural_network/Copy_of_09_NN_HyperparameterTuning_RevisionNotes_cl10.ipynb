{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h2K0xxq6cljh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "- Business Case\n",
        "- EDA\n",
        "- Baseline Model\n",
        "- Regularization\n",
        "  \n",
        "- Dropout\n",
        "  \n",
        "- Batch Normalization\n",
        "  \n",
        "- EarlyStopping\n",
        "  \n"
      ],
      "metadata": {
        "id": "IP_3fjsm0ptK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Business Case"
      ],
      "metadata": {
        "id": "0LjpKcPNU9OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amazon** is facing a high surge of returns on some of its Products, which has led to the downgrade of the company credibility.\n",
        "\n",
        "So they have appointed you as their Data Scientist:\n",
        "- To estimate whether customer will return the product or not\n",
        "- based on the product description, transportation, importance and prices\n",
        "\n",
        "With this, lets load the data:"
      ],
      "metadata": {
        "id": "T8KZCm-KVAyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "XwuPCyL2XA7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!gdown 1mMRZKe5Qm99fJBE9y0mLdvVZYDfHvkxY\n",
        "df = pd.read_csv('Amazon.csv', encoding='latin-1')\n",
        "df.dropna(inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74dAM6jdXA4r",
        "outputId": "10ab42e4-eced-4047-a463-87972fea4852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mMRZKe5Qm99fJBE9y0mLdvVZYDfHvkxY\n",
            "To: /content/Amazon.csv\n",
            "\r  0% 0.00/429k [00:00<?, ?B/s]\r100% 429k/429k [00:00<00:00, 161MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description:**\n",
        "\n",
        "\n",
        "| Id | Features | Description |\n",
        "| :-- | :--| :--|\n",
        "|01| **ID** | ID of Customers|\n",
        "|02| **Warehouse_block** | The Company have big Warehouses which is divided in to block such as A,B,C,D,E|\n",
        "|03|**Mode_of_Shipment**|The Company Ships the products in multiple way such as Ship, Flight and Road.|\n",
        "|04|**Customer_care_calls**|The number of calls made from enquiry for enquiry of the shipment|\n",
        "|05|**Customer_rating**| The company has rated from every customer. 1 is the lowest (Worst), 5 is the highest (Best)|\n",
        "|06|**Cost_of_the_Product**|Price of the Product|\n",
        "|07|**Prior_purchases**|The Number of Prior Purchases of the customer|\n",
        "|08|**Product_importance**|The company has categorized the product in the various parameter such as low, medium, high.|\n",
        "|09|**Gender**|If Customer is a Male or Female|\n",
        "|10|**Discount_offered**|Discount offered on that specific product|\n",
        "|11|**Weight_in_gms**|It is the weight in grams|\n",
        "|12|**Returned**|It is the target variable, where 1 Indicates that the product is returned|\n"
      ],
      "metadata": {
        "id": "Ay72OJs1YkvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "pOL-g6yIXyE3",
        "outputId": "7fd7db33-5955-4bc3-bf8f-3d4c138bf459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID Warehouse_block Mode_of_Shipment  Customer_care_calls  Customer_rating  \\\n",
              "0   1               D           Flight                    4                2   \n",
              "1   2               F           Flight                    4                5   \n",
              "2   3               A           Flight                    2                2   \n",
              "3   4               B           Flight                    3                3   \n",
              "4   5               C           Flight                    2                2   \n",
              "\n",
              "   Cost_of_the_Product  Prior_purchases Product_importance Gender  \\\n",
              "0                  177                3                low      F   \n",
              "1                  216                2                low      M   \n",
              "2                  183                4                low      M   \n",
              "3                  176                4             medium      M   \n",
              "4                  184                3             medium      F   \n",
              "\n",
              "   Discount_offered  Weight_in_gms  Returned  \n",
              "0                44           1233         1  \n",
              "1                59           3088         1  \n",
              "2                48           3374         1  \n",
              "3                10           1177         1  \n",
              "4                46           2484         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35e404b4-c2c5-4b03-91bf-6589fccb9038\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Warehouse_block</th>\n",
              "      <th>Mode_of_Shipment</th>\n",
              "      <th>Customer_care_calls</th>\n",
              "      <th>Customer_rating</th>\n",
              "      <th>Cost_of_the_Product</th>\n",
              "      <th>Prior_purchases</th>\n",
              "      <th>Product_importance</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Discount_offered</th>\n",
              "      <th>Weight_in_gms</th>\n",
              "      <th>Returned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>Flight</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>177</td>\n",
              "      <td>3</td>\n",
              "      <td>low</td>\n",
              "      <td>F</td>\n",
              "      <td>44</td>\n",
              "      <td>1233</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>F</td>\n",
              "      <td>Flight</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>216</td>\n",
              "      <td>2</td>\n",
              "      <td>low</td>\n",
              "      <td>M</td>\n",
              "      <td>59</td>\n",
              "      <td>3088</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>Flight</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>183</td>\n",
              "      <td>4</td>\n",
              "      <td>low</td>\n",
              "      <td>M</td>\n",
              "      <td>48</td>\n",
              "      <td>3374</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B</td>\n",
              "      <td>Flight</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>176</td>\n",
              "      <td>4</td>\n",
              "      <td>medium</td>\n",
              "      <td>M</td>\n",
              "      <td>10</td>\n",
              "      <td>1177</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>C</td>\n",
              "      <td>Flight</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>184</td>\n",
              "      <td>3</td>\n",
              "      <td>medium</td>\n",
              "      <td>F</td>\n",
              "      <td>46</td>\n",
              "      <td>2484</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35e404b4-c2c5-4b03-91bf-6589fccb9038')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35e404b4-c2c5-4b03-91bf-6589fccb9038 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35e404b4-c2c5-4b03-91bf-6589fccb9038');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Number of samples and features of the data:\n",
        "<center>\n",
        "\n",
        "| Records | Features |\n",
        "| :-- | :-- |\n",
        "| 10999 | 12 |"
      ],
      "metadata": {
        "id": "-7-CeysBaVao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmZRPZhEXA2R",
        "outputId": "f21530f7-c07b-433e-c3bc-d8498e7ce2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10999, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['ID','Returned'])\n",
        "y = df['Returned']"
      ],
      "metadata": {
        "id": "lV0ZK-iFlrPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into Train, Validation and Test Data"
      ],
      "metadata": {
        "id": "GBPE05uELQ5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
        "\n",
        "print('Train : ', X_train.shape, y_train.shape)\n",
        "print('Validation:', X_val.shape, y_val.shape)\n",
        "print('Test  : ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "kRH-Lgl2LU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651a441a-0aea-47ab-c44b-a5c31ccb23f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train :  (7039, 10) (7039,)\n",
            "Validation: (1760, 10) (1760,)\n",
            "Test  :  (2200, 10) (2200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA\n"
      ],
      "metadata": {
        "id": "aF3vMis-avQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/646/original/0.png?1693656798\" width=\"800\">"
      ],
      "metadata": {
        "id": "QkjIX-CWQ7vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Which Encoding to use to transform Categorical features ?\n",
        "\n",
        "Ans: Since there are many categories in all the Categorical features,\n",
        "- Which will make the One-Hot Encoding quite large and sparse\n",
        "- Its better to use Target Encoding\n",
        "\n",
        "\n",
        "\n",
        "#### How do target encoding ?\n",
        "Ans: Target Encoding finds the Probability of $y =$(some class$k$) when the Categorical feature $(f) = C_i$\n",
        "- $P(y=k|f=C_i)$\n",
        "- And replace the all the samples which have feature value as $C_i$ to  $P(y=k|f=C_i)$\n",
        "\n",
        "```\n",
        "Suppose y = [0,1] and f = [c1,c2,c3] such that:\n",
        "- out of 200 samples, 50 samples have y = 1, when f = c1\n",
        "-  25 samples have y = 1, when f = c2\n",
        "-  And, 10 samples have y = 1, when f = c3\n",
        "```\n",
        "#### What is the Target Encoding value for the feature ?\n",
        "\n",
        "Ans: $P(Y=1 | f= C_1) = \\frac{50}{200} = 0.25$\n",
        "- $P(Y=1 | f= C_2) = \\frac{25}{200} = 0.13$\n",
        "- $P(Y=1 | f= C_3) = \\frac{10}{200} = 0.05$\n",
        "\n",
        "<br>\n",
        "\n",
        "With this, lets implement Target Encoding\n"
      ],
      "metadata": {
        "id": "hrFp6L9Xxw97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category-encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEOweiX0jVaI",
        "outputId": "1c0cb39b-70a1-46eb-c230-628ee94209b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category-encoders\n",
            "  Downloading category_encoders-2.6.1-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.10.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.13.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category-encoders) (23.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import TargetEncoder\n"
      ],
      "metadata": {
        "id": "f8OzKXfBikQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting all the Categorical Features to Numerical\n",
        "- using TargetEncoding"
      ],
      "metadata": {
        "id": "RAMwtdT-JK1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = TargetEncoder(cols=['Warehouse_block','Mode_of_Shipment','Product_importance','Gender'])\n",
        "X_train = enc.fit_transform(X_train, y_train)\n",
        "\n",
        "X_val = enc.transform(X_val, y_val)\n",
        "X_test = enc.transform(X_test, y_test)\n",
        "\n",
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "jBnXg4VJjc63",
        "outputId": "50e019e6-7a43-4efc-85ef-5ec45f73f838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Warehouse_block  Mode_of_Shipment  Customer_care_calls  \\\n",
              "10286         0.578005          0.608167                    6   \n",
              "7746          0.600336          0.600251                    4   \n",
              "1789          0.601109          0.608167                    5   \n",
              "2521          0.601109          0.600251                    6   \n",
              "10404         0.600336          0.576471                    5   \n",
              "\n",
              "       Customer_rating  Cost_of_the_Product  Prior_purchases  \\\n",
              "10286                2                  196                2   \n",
              "7746                 3                  228                5   \n",
              "1789                 2                  231                4   \n",
              "2521                 4                  221               10   \n",
              "10404                3                  243                6   \n",
              "\n",
              "       Product_importance    Gender  Discount_offered  Weight_in_gms  \n",
              "10286            0.600878  0.596148                10           5180  \n",
              "7746             0.600878  0.599487                 9           1044  \n",
              "1789             0.586928  0.596148                41           2992  \n",
              "2521             0.586928  0.596148                42           2972  \n",
              "10404            0.600878  0.599487                 1           1856  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4af914b-1298-49b7-b636-26df5c729362\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Warehouse_block</th>\n",
              "      <th>Mode_of_Shipment</th>\n",
              "      <th>Customer_care_calls</th>\n",
              "      <th>Customer_rating</th>\n",
              "      <th>Cost_of_the_Product</th>\n",
              "      <th>Prior_purchases</th>\n",
              "      <th>Product_importance</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Discount_offered</th>\n",
              "      <th>Weight_in_gms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10286</th>\n",
              "      <td>0.578005</td>\n",
              "      <td>0.608167</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>196</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600878</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>10</td>\n",
              "      <td>5180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7746</th>\n",
              "      <td>0.600336</td>\n",
              "      <td>0.600251</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>228</td>\n",
              "      <td>5</td>\n",
              "      <td>0.600878</td>\n",
              "      <td>0.599487</td>\n",
              "      <td>9</td>\n",
              "      <td>1044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1789</th>\n",
              "      <td>0.601109</td>\n",
              "      <td>0.608167</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>231</td>\n",
              "      <td>4</td>\n",
              "      <td>0.586928</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>41</td>\n",
              "      <td>2992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2521</th>\n",
              "      <td>0.601109</td>\n",
              "      <td>0.600251</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>221</td>\n",
              "      <td>10</td>\n",
              "      <td>0.586928</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>42</td>\n",
              "      <td>2972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10404</th>\n",
              "      <td>0.600336</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>243</td>\n",
              "      <td>6</td>\n",
              "      <td>0.600878</td>\n",
              "      <td>0.599487</td>\n",
              "      <td>1</td>\n",
              "      <td>1856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4af914b-1298-49b7-b636-26df5c729362')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4af914b-1298-49b7-b636-26df5c729362 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4af914b-1298-49b7-b636-26df5c729362');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Standardization"
      ],
      "metadata": {
        "id": "SpNYhNvm0b00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "- How the data is not Standardized\n",
        "\n",
        "<br>\n",
        "\n",
        "Lets Standardize the data"
      ],
      "metadata": {
        "id": "KPieCMDozCmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "uuhqv6aJTU0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Z7nwu6-kyT6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/647/original/0.png?1693657082\" width=\"600\">"
      ],
      "metadata": {
        "id": "_fUla84wQ3lM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What happens if the data is not standardized ?\n",
        "Ans: if data is not standardized, then suppose:\n",
        "- if one feature has a range from 1 to 1000, and the other has a range from 0 to 1\n",
        "- then the weights $w_1$ and $w_2$ assosicated to these features will vary in value alot\n",
        " - With $w_1$ being a very high value as compared to $w_2$\n",
        "\n",
        "\n",
        "Thus the plot for Loss function ( $L(w,b) = \\frac{1}{2n} \\sum_{i=1}^{i=n} L(\\hat{y_i},y_i)$ ) against the weights for n samples:\n",
        "- Becomes a squashed, very unsymmetric and closed\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Why there  is an issue with a squashed and closed Loss function plot ?\n",
        "Ans: A very small Learning Rate will be required for gradient Descent to reach the global minima\n",
        "- thus increasing the number of steps and time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8LggsJMfYXP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/648/original/0.png?1693657136\" width=\"600\">"
      ],
      "metadata": {
        "id": "6eGOkv12QzZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What happens when data is standardized ?\n",
        "\n",
        "Ans: Since now the data is standardized, it makes:\n",
        "- Range of both the feature 1 and feature 2 from 0 to 1\n",
        "\n",
        "Thus making the weights for both the features close to each other\n",
        "- Therefore the plot for Loss function ( $L(w,b)$)becomes\n",
        " - Spread out and Symmetric\n",
        "\n",
        "\n",
        "#### Why a Spread out and Symmetric Loss function plot works fine ?\n",
        "Ans: We can use a much large Learning rate to quickly reach the global minima"
      ],
      "metadata": {
        "id": "h2K0xxq6cljh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model"
      ],
      "metadata": {
        "id": "Ytb51yBO8MmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data is ready, we can implement\n",
        "- A simple NN model using [tensorflow keras](https://keras.io/api/)\n",
        "- By creating 5 layered NN such that:\n",
        "\n",
        "|Layer| |Descrption|\n",
        "|:--| |:--|\n",
        "|**L1**| |Is the Input Layer |\n",
        "|**L2**| |Contains 256 Neurons|\n",
        "|**L3**| |Contains 128 Neurons|\n",
        "|**L4**| |Contains 64 Neurons|\n",
        "|**L5**| |Is the Output Layer |\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** In Between the layers, we will use:\n",
        "- ReLU as the Activation function\n"
      ],
      "metadata": {
        "id": "q1w9qnrV8JNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# For Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "oDOgqVAIhBeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_baseline():\n",
        "\n",
        "  model = Sequential([\n",
        "                    Dense(256, activation=\"relu\"),\n",
        "                    Dense(128, activation=\"relu\"),\n",
        "                    Dense(64, activation=\"relu\"),\n",
        "                    Dense(1 , activation = 'sigmoid')])\n",
        "  return model"
      ],
      "metadata": {
        "id": "eEMztXLD8Gea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What Loss to use when the final layer Neuron output $(\\hat{y} = a^5_1) \\in [0,1] $ while $y \\in$ { $0,1$ } ?\n",
        "\n",
        "Ans: Recall from Logisitic Regression:\n",
        "- when Sigmoid $σ(z) \\in (0,1)$ and $y = \\in $ {$0,1$}\n",
        "- LogLoss was used. $Logloss (L) = -y  \\times log(\\hat{y}) - (1-y) \\times log(1-\\hat{y}) $\n",
        "\n",
        "Hence here too, LogLoss can be used.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** Logloss in Tensorflow Keras is implemented using ```BinaryCrossentropy()```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DXN-xppGYazV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_baseline()"
      ],
      "metadata": {
        "id": "OYdV7KMBZgyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ```Adam``` as Optimizer and metric being ```Accuracy```"
      ],
      "metadata": {
        "id": "W6RuRyAKtcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "c-mu4pXpYHT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tensorboard"
      ],
      "metadata": {
        "id": "GJ9_QcaNWkEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n"
      ],
      "metadata": {
        "id": "nomKVdudWjAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearing any running logs"
      ],
      "metadata": {
        "id": "x-NOhtDAWs6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "tdk5XskJWi6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "2rvxQMaqWxwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model with epoch=10 and batch size = 128"
      ],
      "metadata": {
        "id": "mnC7eQorrb5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_val, y_val),  epochs=10, batch_size=128, verbose=0,callbacks=[tb_callback])\n"
      ],
      "metadata": {
        "id": "fapXGLVi8RP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check the Model performance on Training and Validation data"
      ],
      "metadata": {
        "id": "Ry0t-XMlriqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWrzmXOBZxPW",
        "outputId": "58da8cee-7b5e-4d16-d447-b7dfdb72150f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.7198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48080185055732727, 0.7198465466499329]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbnetQw1ZxLt",
        "outputId": "605860f4-9b90-45f6-f19e-ec7cae262ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.6415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5430204272270203, 0.6414772868156433]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets plot the Accuracy vs Epochs plots for both training and Validation\n",
        "- for better clarity"
      ],
      "metadata": {
        "id": "Ovt7SPPRtHF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir={log_folder}"
      ],
      "metadata": {
        "id": "3gRS4NJnXBia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "\n",
        "The model has:\n",
        "- training accuracy : 69.9%\n",
        "- and Validation accuracy : 64%\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What can we understand from model's  training accracy being 69.9% and Validaiton Accuracy being 64% ?\n",
        "\n",
        "Ans: Clearly, the model overfits the data meaning:\n",
        "- Model has a low Bias\n",
        "- But a High Variance\n",
        "\n",
        "<br>\n",
        "\n",
        "#### How can we make the baseline model not Overfit ?\n",
        "Ans: By using Regularization\n"
      ],
      "metadata": {
        "id": "8lORN2PDrtCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization"
      ],
      "metadata": {
        "id": "CVNmkuyz61U7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/649/original/0.png?1693657616\" width=\"800\">"
      ],
      "metadata": {
        "id": "wvA7_MS7ujUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What Regularization method to use ?\n",
        "Ans: Recall from ML module, we used L-1 and L-2 regularization methods to\n",
        "- resolve overfitting of the model\n",
        "\n",
        "<br>\n",
        "\n",
        "Also, L2 Regularization for n samples with  d features is defined as:\n",
        "- $L2 = \\frac{λ}{2n} \\sum_{j=0}^{i=d} ||w_j||_2^2 $\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Can we use L2 Regularization in NN ?\n",
        "Ans: No, since in NN there is\n",
        "- L Weight matrices for each layer {$W^1,W^2,..,W^L$}\n",
        "- While in Machine Learning there is only a single weight matrix $W$\n"
      ],
      "metadata": {
        "id": "90mkiVwsursv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/650/original/0.png?1693657661\" width=\"800\">"
      ],
      "metadata": {
        "id": "-wnHxE4gQtkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "#### How to do Regularization in NN ?\n",
        "Ans: Now if we assume that\n",
        "- the number of neurons in the current layer $k$ is $n^k$\n",
        "- and the number of neurons in the previous layer $k-1$ is $n^{k-1}$\n",
        "\n",
        "Then Regularization:\n",
        "- $Reg = \\frac{\\lambda}{2n}\\sum_{k=1}^{k=L}||W^k||_F^2 $\n",
        "\n",
        "<br>\n",
        "\n",
        "Where we define $||W^k||_F^2 $ as:\n",
        "- $\\sum_{i=1}^{n^{k-1}}\\sum_{j=1}^{n^k} (w_{ij}^{k})^2 $\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note**: The term $||W||_F^2$ is called **Forbenius Norm**\n"
      ],
      "metadata": {
        "id": "KzWrsXCi61SU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/651/original/0.png?1693657739\" width=\"800\">"
      ],
      "metadata": {
        "id": "BKHqQPyXQnp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How does weight updation occur with Regularization ?\n",
        "Ans: With regularization the loss function will be defined as:\n",
        "\n",
        "- $Loss = \\frac{1}{2n}\\sum_{i=1}^{i=n}L(\\hat{y_i},y_i) + \\frac{\\lambda}{2n}\\sum_{k=1}^{k=L}||W^k||_F^2 $\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What will be the gradient ($dw^L$) ?\n",
        "Ans: $dw^L$ $=$ (From Backpropagation) $+ \\frac{\\lambda}{n} W^L $\n",
        "\n",
        "#### How do we do the weight updation ?\n",
        "Ans: if Learning Rate is α, then:\n",
        "- Weight updation: $W^L = W^L - α \\times dw^L$\n",
        "\n",
        "Therefore:\n",
        "- $W^L = W^L-\\frac{αλ}{n}W^L - α$(From Backpropagation)\n",
        "\n",
        "On Simpliying:\n",
        "- $W^L = (1-\\frac{αλ}{n}) \\times W^L - α$(From Backpropagation)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** Due to the extra $(1-\\frac{αλ}{n})$,\n",
        "- L2 Regularization is also called **Weight Decay**"
      ],
      "metadata": {
        "id": "amtNBSsY61O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now implement  L2 Regularization on the Baseline Model  "
      ],
      "metadata": {
        "id": "lWDrHZxbYJh5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww6qcDr90Fk8"
      },
      "outputs": [],
      "source": [
        "def create_baseline():\n",
        "    # lambda = 0.01\n",
        "    L2Reg = tf.keras.regularizers.L2(l2=1e-6)\n",
        "    model = Sequential([\n",
        "                    Dense(256, activation=\"relu\", kernel_regularizer = L2Reg ),\n",
        "                    Dense(128, activation=\"relu\", kernel_regularizer = L2Reg),\n",
        "                    Dense(64, activation=\"relu\", kernel_regularizer = L2Reg),\n",
        "                    Dense(1 , activation = 'sigmoid')])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_baseline()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "HL_dK6_sZOB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tensorboard"
      ],
      "metadata": {
        "id": "VP1D_sF4aFSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "-g8Vct9zXhT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "DhDbmXCsXhRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "IRMx10LDeGu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_val, y_val),  epochs=10, batch_size=128, verbose=0,callbacks=[tb_callback])"
      ],
      "metadata": {
        "id": "f0sC4wLCZSqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "hjncXJJveIWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6_VJegzaGou",
        "outputId": "7e3a301e-eb50-4227-86de-91e7ddc70037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.7133\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4818527400493622, 0.7133115530014038]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW06MzIaZcjK",
        "outputId": "b8f9f647-8815-4598-a3d0-fd69372bac75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.6284\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5486941337585449, 0.6284090876579285]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir={log_folder}"
      ],
      "metadata": {
        "id": "JxfASzT9ZFUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "\n",
        "Even with L2 Regularization:\n",
        "- the model performance didnot improve drastically\n",
        "\n"
      ],
      "metadata": {
        "id": "h0nAimLoeEPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dropout"
      ],
      "metadata": {
        "id": "F9XtdHZMJsOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/652/original/0.png?1693658062\" width=\"800\">"
      ],
      "metadata": {
        "id": "cz_s3F_aQhf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is causing the NN model to overfit ?\n",
        "Ans: Observe that:\n",
        "\n",
        "|Layer| |Descrption|\n",
        "|:--| |:--|\n",
        "|**L1**| |Is the Input Layer |\n",
        "|**L2**| |Contains 256 Neurons|\n",
        "|**L3**| |Contains 128 Neurons|\n",
        "|**L4**| |Contains 64 Neurons|\n",
        "|**L5**| |Is the Output Layer |\n",
        "\n",
        "<br>\n",
        "\n",
        "In Layer 2 there are 256 Neurons while Layer 3  contains 128 neurons\n",
        "\n",
        "#### What will be the dimension of Weight Matrix $W^2$ ?\n",
        "Ans: $(256 \\times 128)$\n",
        "\n",
        "<br>\n",
        "\n",
        "Now updating weights of such a high dimensional matrix:\n",
        "- is what making the model complex\n",
        "- which might be leading the model to overfit\n",
        "\n",
        "<br>\n",
        "\n",
        "#### How to resolve this weight update of $W^2 ∈ R^{256 \\times 128}$ such that NN does not overfit ?\n",
        "\n",
        "Ans: By not considering / dropping some weights value while computing $a^3$\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "#### How to drop these weights which make up $a^3$ ?\n",
        "\n",
        "Ans: By creating a mask matrix ($d^2$) which contains some randomly generated numbers between (0,1) such that:\n",
        "\n",
        "- $d^2 = 1 $ if, value of $d^2 >$ rate at which we drop the weight of a neuron ($r$)\n",
        "- else $d^2 = 0$\n",
        "\n",
        "**Note:** This rate $r$ is called as Dropout Rate\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What will be the dimension of this mask matrix $d^2$ ?\n",
        "\n",
        "Ans: Same as the Weight matrix\n",
        "- $d^2 ∈ R^{256 × 128}$\n",
        "\n",
        "#### How do we calculate $a^3$ ?\n",
        "\n",
        "Ans: As $a^3 = g( a^2 × W^2 + b^2 )$, but now we do:\n",
        "- an **elementwise multiplication** between $d^2$ and $W^2$\n",
        " - $ d^2 ∘ W^2 $\n",
        "\n",
        "<br>\n",
        "\n",
        "Hence, we can say:\n",
        "- $a^3 = g(a^2 × (W^2 ∘ d^2) + b^2) $\n",
        "\n",
        "\n",
        "**Note:** This process of removing/ dropping the weights is called **Edge Dropout**\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "There is another approch to **Dropout**, where the Neurons are dropped instead of the  Weights :\n",
        "- By creating the mask $d^2$ for the neurons instead of weights,\n",
        "- And dividing the neurons by a probability factor $p = 1 - r$\n",
        "\n",
        "[Understanding dropout](https://programmathically.com/dropout-regularization-in-neural-networks-how-it-works-and-when-to-use-it/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aLlUB8onJw0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/653/original/0.png?1693658195\" width=\"800\">"
      ],
      "metadata": {
        "id": "47yAn40wvJVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take an example for better Understanding **Edge Dropout**\n",
        "\n",
        "Assuming a NN layer has 2 neurons and the following layer has 3 neurons such that:\n",
        "\n",
        "- $a^2 = [0.5, 0.3]$ , $W^2 = [[1,2,3] ,[4,5,6]]$ and $b^2 = [1, 1, 1]$\n",
        "\n",
        "<br>\n",
        "\n",
        "Now if we create a random probability matrix for values of $W^2$ such that:\n",
        "- $ p(W^2) = [[0.6 , 0.8 , 0.1 ],[0.2 , 0.16 , 0.44]] $\n",
        "\n",
        "<br>\n",
        "\n",
        "#### If the Dropout Rate $r = 0.2$,  what will be $d^2$ ?\n",
        "Ans: Since $d^2 = 1$ if $d^2>0.2$, hence:\n",
        "- $d^2 = [ [1,1,0],[0,0,1] ]$\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "G2z7-DauvTYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/654/original/0.png?1693658300\" width=\"800\">"
      ],
      "metadata": {
        "id": "wP39w9HeQZVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### What will be the value of $d^2 ∘ W^2 $ (Elementwise multiplication) ?\n",
        "Ans: $d^2 ∘ W^2  = [[1,2,0],[0,0,6]]$\n",
        "\n",
        "#### What will be $a^3$ ?\n",
        "\n",
        "Ans: $a^3 = g( [0.5, 0.3]\\times [[1,2,0],[0,0,6]] + [1,1,1])$\n",
        "\n",
        "On solving, we get:\n",
        "- $a^3 = g( [0.5 , 1.0 ,  1.8] + [1,1,1]) = g([1.5, 2.0, 2.8])$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lp2m4n_JlzqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/655/original/0.png?1693658346\" width=\"800\">"
      ],
      "metadata": {
        "id": "XjX-7tRDRTBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Will the Backpropagation for $W^1_{11}$ be affected if we drop $W^2_{11}$ ?\n",
        "\n",
        "\n",
        "Ans: Lets understand it by doing a backpropagation when $W^2_{11}$ is not dropped.\n",
        "\n",
        "- $\\frac{\\partial L}{\\partial W^1_{11}} = \\frac{\\partial L}{\\partial a^3_{1}} \\times  \\frac{\\partial a^3_{1}}{\\partial z^3_{1}} \\times \\frac{\\partial z^3_{1}}{\\partial a^2_{1}}  \\times \\frac{\\partial a^2_{1}}{\\partial z^2_{1}} \\times \\frac{\\partial z^2_{1}}{\\partial a^1_{1}} \\times \\frac{\\partial a^1_{1}}{\\partial z^1_{1}} \\times \\frac{\\partial z^1_{1}}{\\partial W^1_{11}} + \\frac{\\partial L}{\\partial a^3_{1}} \\times  \\frac{\\partial a^3_{1}}{\\partial z^3_{1}} \\times \\frac{\\partial z^3_{1}}{\\partial a^2_{2}}  \\times \\frac{\\partial a^2_{2}}{\\partial z^2_{2}} \\times \\frac{\\partial z^2_{2}}{\\partial a^1_{1}} \\times \\frac{\\partial a^1_{1}}{\\partial z^1_{1}} \\times \\frac{\\partial z^1_{1}}{\\partial W^1_{11}} $\n"
      ],
      "metadata": {
        "id": "EdlIvQgwRd0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/656/original/0.png?1693658419\" width=\"800\">"
      ],
      "metadata": {
        "id": "iCpsRKzCwEfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now if $W^2_{11}$ is dropped:\n",
        "- $\\frac{\\partial L}{\\partial W^1_{11}} = \\frac{\\partial L}{\\partial a^3_{1}} \\times  \\frac{\\partial a^3_{1}}{\\partial z^3_{1}} \\times \\frac{\\partial z^3_{1}}{\\partial a^2_{2}}  \\times \\frac{\\partial a^2_{2}}{\\partial z^2_{2}} \\times \\frac{\\partial z^2_{2}}{\\partial a^1_{1}} \\times \\frac{\\partial a^1_{1}}{\\partial z^1_{1}} \\times \\frac{\\partial z^1_{1}}{\\partial W^1_{11}} $\n",
        "\n",
        "**Note :** Since $W^2_{11}$ is dropped, the weights are not updated only for this weight value.\n",
        "\n",
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "_M4sCjbQwE6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/657/original/0.png?1693658482\" width=\"800\">"
      ],
      "metadata": {
        "id": "6857-2FZRiVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If $r= 0.2$, and the model is trained for 10 epochs and it runs 5 iterations per epoch.\n",
        "\n",
        "#### Can we say, that the weights which are dropped gets their weight updated for all $10 \\times 5 = 50 $ training steps ?\n",
        "Ans: No, because of the fact there is a 20% drop rate:\n",
        "- The weights are updated for only $50 \\times (1-0.2) = 40$ training steps\n",
        "\n",
        "- This dropping of weights helps the neurons to not be inclinced towards any one particular feature\n",
        " - as that feature weight can be dropped off\n",
        "- Thus regularizing the model by giving importance to every neuron/feature.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Then how during test time, the weights of the model accomidate this $40 $ training step ?\n",
        "Ans: During the test time,\n",
        "- Each weight of the model are multiplied with $p = 1- r $\n",
        "\n",
        "#### Will there be dropout during test time ?\n",
        "Ans: No\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYPHE-8ORiny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this lets now implement Dropout using Tensorflow Keras"
      ],
      "metadata": {
        "id": "BBZh-FUda8fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "def create_Dropout():\n",
        "    # lambda = 0.01\n",
        "    L2Reg = tf.keras.regularizers.L2(l2=1e-6)\n",
        "    model = Sequential([\n",
        "                    Dense(256, activation=\"relu\", kernel_regularizer = L2Reg ),\n",
        "                    Dropout(0.3),\n",
        "                    Dense(128, activation=\"relu\", kernel_regularizer = L2Reg),\n",
        "                    Dropout(0.3),\n",
        "                    Dense(64, activation=\"relu\", kernel_regularizer = L2Reg),\n",
        "                    Dense(1 , activation = 'sigmoid')])\n",
        "    return model"
      ],
      "metadata": {
        "id": "3yCdOB2_bEtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_Dropout()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "8lsILdae2ISw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "KZA_LiQmZYaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "DsjX-nLuZgGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "LdeVMrPVcIRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "iZTI5IARcIRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "uB6YWF5YcIRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab4f846-8e02-4f6c-df76-52bc447014a2",
        "id": "4HrAB4XacIRs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.6934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5025047659873962, 0.6934223771095276]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f738744-d59c-428e-9dff-2d2101bd7fd4",
        "id": "FYgPPantcIRs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.6483\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5379933714866638, 0.6482954621315002]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-RTXDa3AZqQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "\n",
        "using Dropout and Regularization,\n",
        "- the model did reduce its overfitting"
      ],
      "metadata": {
        "id": "dz-42oKFmuqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization"
      ],
      "metadata": {
        "id": "f_Ty8i8HeqtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### What other Hyperparameter tuning techniques we can apply to make the model perform better ?\n",
        "Ans: Recall that, we always standardize the inputs to the model for Gradient Descent to quickly reach global minima.\n",
        "\n",
        "Now if we have a four layer NN, such that:\n",
        "\n",
        "- the output of Layer2 ($a^2$) becomes input for layer 3\n",
        "- With weight matrix as $W^3$ with bias as $b^3$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Will the input for layer 3 still be in normalized form ?\n",
        "\n",
        "Ans: **NO**. Clearly, the input to each layer is affected by the weights and biases of the previous layers.\n",
        "\n",
        "So now imagine, there due to data being not normalizied\n",
        "- there is a 0.1% change in data distribution\n",
        "\n",
        "#### What will happen if this change in distribution goes down a 100 layer Neural Network ?\n",
        "\n",
        "Ans: This 0.1% change gets amplified when going down the network\n",
        "\n",
        "- This leads to change in the input distribution to hidden layers of the network\n",
        "- and the weights updation gets impacted\n",
        "\n",
        "This is whats called an **internal covariate shift**  \n",
        "\n",
        "<br>\n",
        "\n",
        "#### Can we normalize $a^2$ so to make $w^3$ and $b^3$ optimum ?\n",
        "\n",
        "Ans: Yes we can, now if we consider m number of neurons in Layer 2,\n",
        "- then $z_i^2.....z_m^2$ becomes the neuron output before the activation function\n",
        "\n",
        "<br>\n",
        "\n",
        "Therefore we can say:\n",
        "\n",
        "- the mean $μ = \\frac{1}{m} ∑_{i=1} ^{i=m} z_i$\n",
        "\n",
        "<br>\n",
        "\n",
        "- the variance $σ^2 =\\frac{1}{m} ∑_{i=1} ^{i=m} (z_i-μ)^2 $\n",
        "\n",
        "<br>\n",
        "\n",
        "Then the normalized $z_i$ ($znorm_i$) becomes:\n",
        "- $znorm_i = \\frac{z_i-μ}{\\sqrt{σ^2+ϵ}}$\n",
        "Where ϵ is a very small value $1e^{-10}$ to prevent the denominator to turn 0 when variance is 0\n",
        "\n",
        "<br>\n",
        "\n",
        "#### but do we want to have all the hidden layers to have outputs with exact mean = 0  and variance = 1 ?\n",
        "Ans: No, because if two hidden layers have the same distribution of mean = 0 and variance = 1\n",
        "- the information learnt about the data for both the layers will be almost same\n",
        "\n",
        "Thus making the use of the 2nd hidden layer redundant.  \n",
        "\n",
        "Please read [Expressive-Power-Of-NeuralNetwork](https://stats.stackexchange.com/questions/272010/batch-normalization-shift-scale-parameters-defeat-the-point) for proof\n",
        "\n",
        "<br>\n",
        "\n",
        "#### how to make the distribution slightly different for each hidden layer ?\n",
        "\n",
        "Ans: By scaling and shifting the $znorm_i$ by using two learnable parameters ($γ, β$) such that:\n",
        "\n",
        "- $ \\hat{z_i} = γ \\times znorm_i + β $\n",
        "\n",
        "\n",
        "**Note:** This Entire  process of normalization with scaling and shifting is known as **Batch Normalization**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kVo8r-cFerAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now implement Batch Normalization in the Baseline Model"
      ],
      "metadata": {
        "id": "VhHMJeuPtKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.activations import relu\n",
        "\n",
        "def create_BatchNormalization_model():\n",
        "    L2Reg = tf.keras.regularizers.L2(l2=1e-6)\n",
        "    model = Sequential([\n",
        "                    Dense(256, kernel_regularizer = L2Reg),\n",
        "                    BatchNormalization(),\n",
        "                    Activation(relu),\n",
        "                    Dropout(0.2),\n",
        "                    Dense(128, kernel_regularizer = L2Reg),\n",
        "                    BatchNormalization(),\n",
        "                    Activation(relu),\n",
        "                    Dense(64,kernel_regularizer = L2Reg ),\n",
        "                    BatchNormalization(),\n",
        "                    Activation(relu),\n",
        "                    Dense(3)])\n",
        "    return model"
      ],
      "metadata": {
        "id": "mV0l_sJ-KvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_BatchNormalization_model()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wymkDmtduMfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "DiHKakyodJgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "c5w3fuqHdNvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing epoch to 15 now"
      ],
      "metadata": {
        "id": "u3XPz8shebiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_val, y_val),  epochs=15, batch_size=128, verbose=0,callbacks=[tb_callback])\n"
      ],
      "metadata": {
        "id": "dwX_MGt0KvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluting the model"
      ],
      "metadata": {
        "id": "TqbUOjHIwjQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zej0e-jqtPhm",
        "outputId": "85e597db-7b13-45c1-a10c-f6b5a0185040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 1s 2ms/step - loss: 2.3278 - accuracy: 0.6453\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.327779531478882, 0.6452621221542358]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S18oKfVRwlY7",
        "outputId": "d9a85527-2e2d-4e83-85ad-37e889df74ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 2.5997 - accuracy: 0.6324\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5997164249420166, 0.6323863863945007]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir={log_folder}"
      ],
      "metadata": {
        "id": "_Ri7UN89dUh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see after applying Batch Normalization :\n",
        "- L2 Regularization worked\n",
        "- And made the model not overfit the data  "
      ],
      "metadata": {
        "id": "dAWkM6JHwwrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping"
      ],
      "metadata": {
        "id": "RvnqYEH7-gFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/045/658/original/0.png?1693660433\" width=\"800\">"
      ],
      "metadata": {
        "id": "Fp_1FpHuRt5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "\n",
        "When using Batch Normalization,\n",
        "- around epoch 8 the  Validation Accuracy is maximum,\n",
        "- and then it starts to decrease\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Can there be a way to make the model not update the weights after the validation accuracy reaches maximum ?\n",
        "\n",
        "Ans:  Yes, by using callbacks to stop the training when:\n",
        "- The validation accuracy starts decreasing\n",
        "- or validation loss starts to increase\n",
        "\n",
        "<br>\n",
        "\n",
        "#### How to know if the model has reached maximum validation accuracy  or not?\n",
        "\n",
        "Ans: By using callbacks such that:\n",
        "- One callback stores the weights of model when best validation accuracy is attained\n",
        "- While the other callback, Stops the training:\n",
        " - after not finding a better validation accuracy, when the model is trained for some epoch ($τ$)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note**: Keras uses ```EarlyStoppingCallback``` for:\n",
        "- stopping the training after no better Validation accuracy attained when ran for some epoch ($τ$)    \n",
        "\n",
        "Also keras uses another callback  ```ModelCheckpointCallback``` for:\n",
        "- Storing the weights of the model which had the best Validation Accuracy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jew6kLIj-gb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_BatchNormalization_model()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "XhfUkrC4cO_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "2J96OWMTeKmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "now = datetime.now()\n",
        "log_folder = \"tf_logs/.../\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=log_folder, histogram_freq=1)"
      ],
      "metadata": {
        "id": "HbSJoLGaePOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EarlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50,  restore_best_weights=True)\n",
        "ModelCheckpointCallback = tf.keras.callbacks.ModelCheckpoint(filepath='tf_model.h5',\n",
        "                                                             monitor='val_accuracy',\n",
        "                                                             save_best_only=True,\n",
        "                                                             mode='max')"
      ],
      "metadata": {
        "id": "L7q1ysrOkyAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_val, y_val),  epochs=15, batch_size=128, verbose=0, callbacks=[EarlyStoppingCallback, ModelCheckpointCallback,tb_callback])\n"
      ],
      "metadata": {
        "id": "iMpid_t6kx-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir={log_folder}"
      ],
      "metadata": {
        "id": "5_HNJwU8er84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the model where the EarlyStopping took place"
      ],
      "metadata": {
        "id": "-MHLPVO-iMLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_BatchNormalization_model()\n",
        "model.build(input_shape =(None,10))"
      ],
      "metadata": {
        "id": "5feDmUe5gczB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('tf_model.h5')"
      ],
      "metadata": {
        "id": "ciHOlPL6ettY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZNZcHP_Vhsao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlvgO0GDkx70",
        "outputId": "c9a45f95-e3b9-48f5-be61-7742b9a9eb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220/220 [==============================] - 1s 3ms/step - loss: 1.2022 - accuracy: 0.6465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2022379636764526, 0.6465407013893127]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7POpc4elF6a",
        "outputId": "d4657565-905c-4c98-9d94-ea80aca28001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 1.3301 - accuracy: 0.6301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3301416635513306, 0.6301136612892151]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nJSRL-fnKhg",
        "outputId": "3a7a9882-25df-42a0-c9e9-db73936cfc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2194 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2193852663040161, 0.628636360168457]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlh9IyjCnq7z",
        "outputId": "c49493bc-32fd-48bb-92e3-42f6372b9b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As```output``` is just the probability of $Y=1$ or $Y=0$ based on the feature X,\n",
        "- Using a threshold $ γ = 0.5 $ so that ```output``` $\\in ${$0,1$}"
      ],
      "metadata": {
        "id": "SocsYxFRrzXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.array([1 if i > 0.5 else 0  for i in output])"
      ],
      "metadata": {
        "id": "hYKgsQ08n52R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Confusion Matrix"
      ],
      "metadata": {
        "id": "WlSF91w8sSsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.colorbar()\n",
        "\n",
        "class_names = ['Returned','Not Returned']\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=45)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# Normalize the confusion matrix.\n",
        "cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "# Use white text if squares are dark; otherwise black.\n",
        "threshold = cm.max() / 2.\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color =  \"black\"\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "6otQpIoiqAPw",
        "outputId": "c0705a64-baf6-488c-c20f-e13f9666c666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, -28.828503717825924, 'Predicted label')"
            ]
          },
          "metadata": {},
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observe**\n",
        "\n",
        "Though the model performs pretty good , it still has a significantly **high False Positive**:\n",
        "- Showing that maybe a more complex model might be needed to for a better performance"
      ],
      "metadata": {
        "id": "QGncuodUx-rQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting ROC Curve"
      ],
      "metadata": {
        "id": "DpN7WUIDupbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr,tpr,_ = sklearn.metrics.roc_curve(y_test,output.squeeze(axis=1))"
      ],
      "metadata": {
        "id": "ZESRwzgquI2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.plot([0, 1], ls=\"--\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate' )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7kVTeepxuUIz",
        "outputId": "f119996c-f7f4-40c2-af3a-f6d0d0592b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**observe**\n",
        "\n",
        "Clearly the model outperforms a mean model"
      ],
      "metadata": {
        "id": "vGu7wkluzFwb"
      }
    }
  ]
}